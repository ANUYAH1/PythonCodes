{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_folder=os.path.join('data','texts_18-80')\n",
    "all_files=[os.path.join(data_folder, fname) for fname in os.listdir(data_folder)]\n",
    "\n",
    "train_6_9={}\n",
    "test_6_9={}\n",
    "count=0\n",
    "\n",
    "for d in all_files:\n",
    "    bname=os.path.basename(d)\n",
    "    file_num=os.path.splitext(bname)[0]\n",
    "    with open(d, 'r') as f:\n",
    "        if count <=5:\n",
    "            test_6_9[file_num]=f.read()\n",
    "        elif count in range(5, 30):\n",
    "            train_6_9[file_num]=f.read()\n",
    "        count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def syllables(word):\n",
    "    count = 0\n",
    "    vowels = 'aeiou'    \n",
    "    if word[0] in vowels:\n",
    "        count +=1\n",
    "    for index in range(1,len(word)):\n",
    "        if word[index] in vowels and word[index-1] not in vowels:\n",
    "            count +=1\n",
    "        if word.endswith('e'):\n",
    "            count -= 1\n",
    "        if word.endswith('le'):\n",
    "            count+=1\n",
    "        if word.endswith('ie'):\n",
    "            count+=1\n",
    "        if count == 0:\n",
    "            count +=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Readability(text):    \n",
    "    cleaned_words=[[]]    \n",
    "    for k, v in text.items():\n",
    "        values=v\n",
    "        key=k\n",
    "        split_sentences=tokenizer.tokenize(str(values).replace(\"\\\\n\",\" \"))\n",
    "    tokens=[x.split() for x in split_sentences]\n",
    "    for w in tokens:\n",
    "        cleaned_words = [[''.join(c for c in s if c not in string.punctuation) for s in m] for m in tokens]\n",
    "        cleaned_words = [[s.lower() for s in k if s] for k in cleaned_words]\n",
    "        cleaned_words=[[w for w in k if w.isalpha()] for k in cleaned_words]\n",
    "    words=[a for m in cleaned_words for a in m ]\n",
    "    Total_sentences=len(cleaned_words)\n",
    "    Total_words=len(words)\n",
    "    Total_Syllable=0\n",
    "    for w in words:\n",
    "        Total_Syllable+=syllables(w)\n",
    "    A=(Total_words)/(Total_sentences)\n",
    "    B=(Total_Syllable)/(Total_words)\n",
    "    flesch_kincaid_difficulty=(206.835-(1.015*A)-(84.6*B))\n",
    "    flesch_kincaid_grade_level=(0.39*A)+(11.8*B)-15.59                 \n",
    "    with open('data/readability.txt','a', encoding=\"utf-8\") as f:\n",
    "        print('{} {} {}'.format(key, round(flesch_kincaid_difficulty), round(flesch_kincaid_grade_level), 'label'), file=f)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lake_Titicaca</td>\n",
       "      <td>61</td>\n",
       "      <td>9</td>\n",
       "      <td>18-80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vincent_van_Gogh</td>\n",
       "      <td>61</td>\n",
       "      <td>10</td>\n",
       "      <td>18-80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Justin_Beiber</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>18-80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rembrandt</td>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>18-80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iliad</td>\n",
       "      <td>59</td>\n",
       "      <td>11</td>\n",
       "      <td>18-80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Title  Difficulty  Grade Category\n",
       "0     Lake_Titicaca          61      9    18-80\n",
       "1  Vincent_van_Gogh          61     10    18-80\n",
       "2     Justin_Beiber          58     10    18-80\n",
       "3         Rembrandt          50     13    18-80\n",
       "4             Iliad          59     11    18-80"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1=pd.read_csv('data/readability_18_80_train.txt', names=['Title', 'Difficulty', 'Grade', 'Category'], delimiter='  ')\n",
    "model1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elephants.pdf</td>\n",
       "      <td>71</td>\n",
       "      <td>7</td>\n",
       "      <td>6-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grandmas-glasses-FKB-kids-stories.pdf</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>6-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The-story-of-stories-FKB-kids-books.pdf</td>\n",
       "      <td>66</td>\n",
       "      <td>7</td>\n",
       "      <td>6-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Free-Kids-Books-Spelling-Lists-workbook-3-comi...</td>\n",
       "      <td>37</td>\n",
       "      <td>21</td>\n",
       "      <td>6-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cats-FKB-Kids-Stories.pdf</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>6-9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  Difficulty  Grade  \\\n",
       "0                                      Elephants.pdf          71      7   \n",
       "1              grandmas-glasses-FKB-kids-stories.pdf          70      6   \n",
       "2            The-story-of-stories-FKB-kids-books.pdf          66      7   \n",
       "3  Free-Kids-Books-Spelling-Lists-workbook-3-comi...          37     21   \n",
       "4                          Cats-FKB-Kids-Stories.pdf          70      6   \n",
       "\n",
       "  Category  \n",
       "0      6-9  \n",
       "1      6-9  \n",
       "2      6-9  \n",
       "3      6-9  \n",
       "4      6-9  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2=pd.read_csv('data/readability_6_9_train.txt', names=['Title', 'Difficulty', 'Grade', 'Category'], delimiter=' ')\n",
    "model2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The-Blob-The-Frog-The-DOG-and-The-Girl.pdf</td>\n",
       "      <td>88</td>\n",
       "      <td>4</td>\n",
       "      <td>10-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sugar-the-Robot-and-the-race-to-save-the-Earth...</td>\n",
       "      <td>85</td>\n",
       "      <td>4</td>\n",
       "      <td>10-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alice-in-Wonderland.pdf</td>\n",
       "      <td>87</td>\n",
       "      <td>6</td>\n",
       "      <td>10-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gifted1.pdf</td>\n",
       "      <td>91</td>\n",
       "      <td>3</td>\n",
       "      <td>10-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beekle-Henry.pdf</td>\n",
       "      <td>74</td>\n",
       "      <td>7</td>\n",
       "      <td>10-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  Difficulty  Grade  \\\n",
       "0         The-Blob-The-Frog-The-DOG-and-The-Girl.pdf          88      4   \n",
       "1  Sugar-the-Robot-and-the-race-to-save-the-Earth...          85      4   \n",
       "2                            Alice-in-Wonderland.pdf          87      6   \n",
       "3                                        gifted1.pdf          91      3   \n",
       "4                                   Beekle-Henry.pdf          74      7   \n",
       "\n",
       "  Category  \n",
       "0    10-13  \n",
       "1    10-13  \n",
       "2    10-13  \n",
       "3    10-13  \n",
       "4    10-13  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3=pd.read_csv('data/readability_10_13_train.txt', names=['Title', 'Difficulty', 'Grade', 'Category'], delimiter=' ')\n",
    "model3[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Sentences(text):    \n",
    "    cleaned_words=[[]] #given the sentences, put the words in a multidimensional array    \n",
    "    for k, v in text.items(): #iterating over a dictonary\n",
    "        values=v\n",
    "        key=k        \n",
    "        for kk in key: #for each key, access the values \"which are sentences in this case\"\n",
    "            split_sentences=tokenizer.tokenize(str(values).replace(\"\\\\n\",\" \")) #use nltk sentence tokenizer to split into sentences\n",
    "        tokens=[x.split() for x in split_sentences] #get the unique words in each sentence\n",
    "        cleaned_words = [[''.join(c for c in s if c not in string.punctuation) for s in m] for m in tokens] #remove punctuations\n",
    "        cleaned_words = [[s.lower() for s in k if s] for k in cleaned_words] #lowercase the words\n",
    "        cleaned_words=[[w for w in k if w.isalpha()] for k in cleaned_words] #ignore non-aplhabets      \n",
    "        Total_sentences=[' '.join(c for c in s ) for s in cleaned_words]  #join them back to be words, so they don't appear as list items      \n",
    "        for s in Total_sentences: #for each sentence identified with the key, write to the respective file\n",
    "            with open('data/Sentences_'+key+'_.txt', 'a') as f: #i identified the files with the key\n",
    "                print(s, file=f)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_docs={}\n",
    "dummy_docs['frozen_disney']='Frozen is a 2013 American 3D computer-animated musical fantasy film produced by Walt Disney Animation Studios and released by Walt Disney Pictures.[4] It is the 53rd Disney animated feature film. Inspired by Hans Christian Andersens fairy tale The Snow Queen,[5] the film tells the story of a fearless princess who sets off on a journey alongside a rugged iceman, his loyal pet reindeer, and a naïve snowman to find her estranged sister, whose icy powers have inadvertently trapped the kingdom in eternal winter.'\n",
    "dummy_docs['empire']='Empire is an American musical drama television series created by Lee Daniels and Danny Strong which debuted on January 7, 2015. Although it is filmed in Chicago,[2][3] the show is set in New York. It centers on a fictional hip hop music and entertainment company, Empire Entertainment, and the drama among the members of the founders family as they fight for control of it.'\n",
    "dummy_docs['finding dory']='Finding Dory is a 2016 American 3D computer-animated comedy-drama adventure film produced by Pixar Animation Studios and released by Walt Disney Pictures. Directed by Andrew Stanton with co-direction by Angus MacLane,[5][6] the screenplay was written by Stanton and Victoria Strouse.[7] The film is a sequel/spinoff[8][9] to 2003s Finding Nemo and features the returning voices of Ellen DeGeneres and Albert Brooks, with Hayden Rolence (replacing Alexander Gould), Ed O Neill, Kaitlin Olson, Ty Burrell, Diane Keaton and Eugene Levy joining the cast. Finding Dory focuses on the amnesiac fish Dory, who journeys to be reunited with her parents.[10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Sentences(dummy_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Readability(dummy_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
